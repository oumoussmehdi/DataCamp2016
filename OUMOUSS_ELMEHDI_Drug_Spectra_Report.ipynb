{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Camp 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <a href=http://www.datascience-paris-saclay.fr/>Paris Saclay Center for Data Science</a> </h1>\n",
    "\n",
    "<h2> RAMP on qualitative and quantitative non-invasive monitoring of anti-cancer drugs </h2>\n",
    "\n",
    "<i>Camille Marini (LTCI/CNRS), Alex Gramfort (LTCI/Télécom ParisTech), Sana Tfaili (Lip(Sys)²/UPSud), Laetitia Le (Lip(Sys)²/UPSud), Mehdi Cherti (LAL/CNRS), Balázs Kégl (LAL/CNRS)</i>\n",
    "\n",
    "<i>Report by: OUMOUSS EL MEHDI</i>\n",
    "Github: oumoussmehdi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New to the field of data science, yet very passionate about it, I learned a lot from this\n",
    "experience. \n",
    "\n",
    "At the beginning, my approach was a more or less what I would call a brute force approach \n",
    "to the problem, mainly due to my lake knowledge of the use cases of machine learning algorithms.\n",
    "Therefore, I have tried several algorithms independently and sometimes combined them. which \n",
    "obviousely didn't yield to good results, with some exceptional cases. I even created a \n",
    "table to track the performance of each algorith I used, in order to compare them.\n",
    "\n",
    "So, I changed my approach, by have several reading about the different algorithms that I had contact with and tried to understand their concept more properly and especially when it is recommanded to use them. In other words, the Use Cases.\n",
    "\n",
    "At this level, I started treating the problem in a more scientific way.\n",
    "And here after are the steps, I followed:\n",
    "    1. Analyse the data and provided plots, in order to get insights.\n",
    "    2. Come up with a classifier, with a low error\n",
    "    3. Create a good regressor, with low mare.\n",
    "    4. Feature extraction, in order to improve the performance of the predictif model\n",
    "    5. Fine-tuning (didn't reach this step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before even going to the details of my work, here after is the performance I achieved throught my submissions:\n",
    "\n",
    "* 1st: (Modified the Classifier)\n",
    "* 2nd: (Modified the Classifier)\n",
    "* 3rd: (Modified the Classifier, Regressor and the Classifier's Feature Extraction)      \n",
    "\n",
    "Performance:             \n",
    "      \n",
    "|     | combined | error | mare  |\n",
    "|-----|----------|-------|-------|\n",
    "| 1st | 0.109    | 0.065 | 0.195 |\n",
    "| 2nd | 0.153    | 0.120 | 0.219 |\n",
    "| 3rd | 0.165    | 0.058 | 0.378 |\n",
    "\n",
    "Time spent on the project : \n",
    "One day and half (The camp was in Overlap with other courses and labs in my master programm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What I learned : Takeoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Working on real data.\n",
    "* Expanded my knowledge about different machine learning algorithms.\n",
    "* Familiarized with feature extraction, a technique that i hadn't worked on much.\n",
    "* I am sure, I will learn a lot from the collaborative session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The algorithms I used: (Reference: Wikipedia)\n",
    "\n",
    "Stochastic gradient descent:\n",
    "A stochastic approximation of the gradient descent optimization method \n",
    "for minimizing an objective function that is written as a sum of differentiable functions\n",
    "    \n",
    "Principal component analysis (PCA): \n",
    "a statistical procedure that uses an orthogonal transformation to convert \n",
    "a set of observations of possibly correlated variables into a set of values \n",
    "of linearly uncorrelated variables called principal components. \n",
    "\n",
    "Gradient boosting: \n",
    "A technique for regression and classification problems, \n",
    "which produces a prediction model in the form of an ensemble of weak prediction models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.n_components = 10\n",
    "        self.n_estimators = 500 \n",
    "        \n",
    "        sgd = linear_model.SGDClassifier()\n",
    "        pca = PCA(n_components=self.n_components)\n",
    "        gbc = GradientBoostingClassifier(n_estimators=self.n_estimators, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "      \n",
    "        self.clf = Pipeline([\n",
    "            ('sgd', sgd),\n",
    "            ('pca', pca),\n",
    "            ('clf', gbc)\n",
    "        ])\n",
    "        #\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the regressor, after several experiments with different regressors (xxxxx) , \n",
    "the combinasion of PCA and GradientBoostingRegressor was simply the best in matter of \n",
    "performance, even when the classifier is different.\n",
    "\n",
    "That is why, I kept this regressor all along my experiment. However, In my last submission, after noticing that the change in the parameters (components, etc) plays a big role in \n",
    "enhancing the performance, I tried to follow the same appraoch with the regressor, but that\n",
    "did yield to a bigger mare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "class Regressor(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.n_components = 10\n",
    "        self.n_estimators = 200\n",
    "        self.learning_rate = 0.2\n",
    "        self.list_molecule = ['A', 'B', 'Q', 'R']\n",
    "        self.dict_reg = {}\n",
    "        \n",
    "        pca =  PCA(n_components=self.n_components)\n",
    "        gbr = GradientBoostingRegressor(n_estimators=self.n_estimators,learning_rate=self.learning_rate,random_state=42)\n",
    "        for mol in self.list_molecule:\n",
    "            self.dict_reg[mol] = Pipeline([\n",
    "               ('r0', pca),('r1', gbr)\n",
    "                ])\n",
    "\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        for i, mol in enumerate(self.list_molecule):\n",
    "            ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]\n",
    "            XX_mol = X[ind_mol]\n",
    "            y_mol = y[ind_mol]\n",
    "            self.dict_reg[mol].fit(XX_mol, np.log(y_mol))\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for i, mol in enumerate(self.list_molecule):\n",
    "            ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]\n",
    "            XX_mol = X[ind_mol]\n",
    "            y_pred[ind_mol] = np.exp(self.dict_reg[mol].predict(XX_mol))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my 3rd submission, I want it to explore my models reaction, if I change some features.\n",
    "The plots :\"Raman spectra for each type of molecule\" and \n",
    "\"Mean Raman spectra for each concentration value\". see (drug_spectra_starting_kit)\n",
    "\n",
    "were very interessting int the sense that the region approximately between 1000 and 1600, \n",
    "showed a different behavior. Therefore, I want to emphasize this behavior, \n",
    "by chunking the spectra dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "class FeatureExtractorClf():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        XX = np.array([np.array(dd) for dd in X_df['spectra']])\n",
    "        for item in XX : \n",
    "            item = item[1000:1600]\n",
    "        return XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I think that this helped reduce the error of the classifier, since it was the best compared\n",
    "to the other classifiers. Yet, the mare of the regressor was higher ?? \n",
    "(needs further investigation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was planning also to do the following experiments:\n",
    "    * see how the classifier will react, when we will add 'vial' and 'solute'\n",
    "    to the dataframe.\n",
    "    * Investigate also how Intensity and frequency, can play a role to enhance \n",
    "    the model's performance\n",
    "    * Maybe, try to create a feature from already existing ones and see if it can\n",
    "    help improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My work isn't the best, however, I learned a lot from this camp. And I am willing to improve my skills in matter of data science.\n",
    "So, Thank you!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
